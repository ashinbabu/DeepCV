{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Creating the dataset"
      ],
      "metadata": {
        "id": "NnUDRGool1H9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyDNSxRfhBfA"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "# load the apple image\n",
        "img = cv2.imread('/content/apple.jpg')\n",
        "\n",
        "# get the size of the apple image\n",
        "apple_size = img.shape[0]\n",
        "\n",
        "# create directories for each quadrant\n",
        "quadrant_names = ['quadrant_0', 'quadrant_1', 'quadrant_2', 'quadrant_3']\n",
        "for quadrant_name in quadrant_names:\n",
        "    os.makedirs(quadrant_name, exist_ok=True)\n",
        "\n",
        "# create 100 images for each quadrant\n",
        "quadrants = [(0, 0), (200, 0), (0, 200), (200, 200)]\n",
        "for i, q in enumerate(quadrants):\n",
        "    x, y = q\n",
        "    for j in range(100):\n",
        "        quadrant_img = np.zeros((400, 400, 3), np.uint8)\n",
        "        \n",
        "        # randomize the position of the apple image in the quadrant\n",
        "        dx = random.randint(0, 200 - apple_size)\n",
        "        dy = random.randint(0, 200 - apple_size)\n",
        "        quadrant_img[y+dy:y+dy+apple_size, x+dx:x+dx+apple_size] = img\n",
        "        \n",
        "        filename = f\"apple_{i}_{j}.jpg\"\n",
        "        filepath = os.path.join(quadrant_names[i], filename)\n",
        "        cv2.imwrite(filepath, quadrant_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Model"
      ],
      "metadata": {
        "id": "LhaOMKy8aGOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# set the directory containing the apple images\n",
        "directory = 'apple_images'\n",
        "\n",
        "# load the apple images and their labels\n",
        "images = []\n",
        "labels = []\n",
        "for i in range(4):\n",
        "    for j in range(100):\n",
        "        filename = f\"apple_{i}_{j}.jpg\"\n",
        "        filepath = os.path.join(directory, f\"quadrant_{i}\", filename)\n",
        "        img = cv2.imread(filepath)\n",
        "        images.append(img)\n",
        "        labels.append(i)\n",
        "\n",
        "# convert the images and labels to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "id": "ZHYUoXURaF8K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}